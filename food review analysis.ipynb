{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/ernestng/Desktop/projects/foodreview/amazon-fine-food-reviews/')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fooddf = pd.read_csv(\"./Reviews.csv\")\n",
    "fooddf = fooddf[['Score', 'Text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check counts of each rating(1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>363122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text\n",
       "Score        \n",
       "1       52268\n",
       "2       29769\n",
       "3       42640\n",
       "4       80655\n",
       "5      363122"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fooddf.groupby('Score').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a significantly larger number of reviews with rating of 5, so I plan to use random under sampling to balance the data.\n",
    "\n",
    "Random Under sampling aims to balance class distribution by randomly eliminating majority class examples. This is done until the majority and minority class instances are balanced out. In this approach, I reduce the data from higher class (data with 4 and 5 rating) to match the data with lower class(data with 1 and 2 rating).\n",
    "\n",
    "I can eliminate data with 3 rating since I want to create a binary classifer and rating 3 is really sitting on the fence, although we can keep in mind rating 3 might be useful for multiclass classifier\n",
    "\n",
    "counts of rating 1-2 : 82037\n",
    "counts of rating 4-5 : 443777 (I will randomly pick 82037 data points from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>My cats have been happily eating Felidae Plati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>I love eating them and they are good for watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>The candy is just red , No flavor . Just  plan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Score                                               Text\n",
       "1       1  Product arrived labeled as Jumbo Salted Peanut...\n",
       "3       2  If you are looking for the secret ingredient i...\n",
       "12      1  My cats have been happily eating Felidae Plati...\n",
       "16      2  I love eating them and they are good for watch...\n",
       "26      1  The candy is just red , No flavor . Just  plan..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_low = fooddf[fooddf['Score']<3]\n",
    "food_low.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_high = fooddf[fooddf['Score']>3]\n",
    "food_high.head()\n",
    "food_high_resampled = food_high.sample(n = 82037, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    82037\n",
       "0    82037\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_food = pd.concat([food_low,food_high_resampled])\n",
    "def sentiment(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "new_food[\"sentiment\"] = new_food.Score.map(sentiment)\n",
    "new_food.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>My cats have been happily eating Felidae Plati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>I love eating them and they are good for watch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>The candy is just red , No flavor . Just  plan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410093</th>\n",
       "      <td>5</td>\n",
       "      <td>Loved this for breakfast as a child.  My child...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217854</th>\n",
       "      <td>5</td>\n",
       "      <td>After a lengthy trek in the Himalayan Range, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426527</th>\n",
       "      <td>5</td>\n",
       "      <td>These wafers are wonderfully light and taste j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395540</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm a huge fan of Earnest Eats with my favorit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167235</th>\n",
       "      <td>5</td>\n",
       "      <td>My dogs are all on very limited ingredient die...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164074 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score                                               Text  sentiment\n",
       "1           1  Product arrived labeled as Jumbo Salted Peanut...          0\n",
       "3           2  If you are looking for the secret ingredient i...          0\n",
       "12          1  My cats have been happily eating Felidae Plati...          0\n",
       "16          2  I love eating them and they are good for watch...          0\n",
       "26          1  The candy is just red , No flavor . Just  plan...          0\n",
       "...       ...                                                ...        ...\n",
       "410093      5  Loved this for breakfast as a child.  My child...          1\n",
       "217854      5  After a lengthy trek in the Himalayan Range, t...          1\n",
       "426527      5  These wafers are wonderfully light and taste j...          1\n",
       "395540      5  I'm a huge fan of Earnest Eats with my favorit...          1\n",
       "167235      5  My dogs are all on very limited ingredient die...          1\n",
       "\n",
       "[164074 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X input : Text\n",
    "y output : sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_food.Text, new_food.sentiment, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data, I use CountVectorizer() to convert text documents to matrix of token counts. \n",
    "\n",
    "This configuration tokenize the strings and convert them to lower case and build a vocabulary of comma separated tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvect = CountVectorizer().fit(X_train)\n",
    "xtrain_vect = xvect.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is further processed by applying Tfidf Vectorizer, which helps us to give more weight-age to important words which less important words for the case study would be given more weights.\n",
    "Since, our code is based on counting the frequency of each word in the document, so if certain words like ‘the’, ‘if’ etc. which are present more frequently then words which are more important such as ‘buy’,’product’ etc. , which gives us the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58973"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvect = TfidfVectorizer().fit(X_train)\n",
    "xtrain_vect = xvect.transform(X_train)\n",
    "len(xvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I further improve my model, for example it would help us to differentiate between ‘good’ and ‘not good’ as it would take both words together(for bi gram count pairs). Also, it would help us to work with more features. I have set the n-grams in the range of 1–2 which helps us to extract features for 1 and 2 grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6002749"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvect = TfidfVectorizer(ngram_range = (1,3)).fit(X_train)\n",
    "xtrain_vect = xvect.transform(X_train)\n",
    "len(xvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit this model, I am going to use Logistic Regression and Multinomial Naive Bayes Algorithm and I will compare both the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_model = MultinomialNB()\n",
    "food_model.fit(xtrain_vect, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9249126449932409"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = food_model.predict(xvect.transform(X_test))\n",
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters I changed: \n",
    "1) multi_class='ovr' (Binary problem is fit for each label)\n",
    "2) n_jobs=1 (Number of CPU cores used when parallelizing over classes if multi_class=’ovr’)\n",
    "3) solver='liblinear' (Algorithm to use when optimizing over a small dataset such as this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_LRmodel = LogisticRegression(n_jobs=1,multi_class='ovr',solver='liblinear')\n",
    "food_LRmodel.fit(xtrain_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9358109760522249"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsLR = food_LRmodel.predict(xvect.transform(X_test))\n",
    "roc_auc_score(y_test, predictionsLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression(LR) gives us a better AUC score than Multinomial NB(MNB). \n",
    "LR gives better prediction than MNB, hence I will the LR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to determine review input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictreview(x):\n",
    "    rev = food_LRmodel.predict(xvect.transform(x))\n",
    "    rev_list = np.where(rev==1,\"Positive\",\"Negative\").tolist()\n",
    "    return dict(zip(x, rev_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the ayam penyet i had today was awesome!': 'Positive',\n",
       " 'good plate of fried rice, but expensive': 'Positive',\n",
       " 'portion too small': 'Negative',\n",
       " 'great value for money!': 'Positive',\n",
       " 'cheap and good food': 'Positive',\n",
       " 'cheap food': 'Negative',\n",
       " 'waste of money': 'Negative',\n",
       " 'terrible service and the food is badly done': 'Negative',\n",
       " 'edible but i will not visit again': 'Negative',\n",
       " 'wonderful service, i will definitely visit again': 'Positive',\n",
       " 'not very good': 'Negative'}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"the ayam penyet i had today was awesome!\",\n",
    "         \"good plate of fried rice, but expensive\",\n",
    "        \"portion too small\",\n",
    "        \"great value for money!\",\n",
    "        \"cheap and good food\",\n",
    "        \"cheap food\",\n",
    "        \"waste of money\",\n",
    "        \"terrible service and the food is badly done\",\n",
    "        \"edible but i will not visit again\",\n",
    "       \"wonderful service, i will definitely visit again\",\n",
    "       \"not very good\"]\n",
    "\n",
    "test_chinese = [\"hen haochi\", \n",
    "                \"hen bu haochi\", \n",
    "                \"shiwu bu hao chi\",\n",
    "                \"wo bu xi huan shiwu\",\n",
    "                \"wo xi huan shiwu\"]\n",
    "predictreview(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included some hanyupinyin to test if my model can understand chinese words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hen haochi': 'Positive',\n",
       " 'hen bu haochi': 'Negative',\n",
       " 'shiwu bu hao chi': 'Negative',\n",
       " 'wo bu xi huan shiwu': 'Negative',\n",
       " 'wo xi huan shiwu': 'Positive'}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictreview(test_chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix looks good, number of true positives and true negatives are quite even "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7743,  479],\n",
       "       [ 574, 7612]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictionsLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall_score tells us intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298802834107012"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, predictionsLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: This model is trained against Amazon Fine Food Dataset with 164074 reviews after cleaning the data. We have achieved an accuracy score of around 93.57% which is quite good. I believe when I train this model against a larger dataset, I can achieve a much higher accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
